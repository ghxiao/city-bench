{"name":"City-bench","tagline":"","body":"city-bench\r\n==========\r\n\r\n`city-bench` is a publicly available collection of geographic datasets for OBDA systems.\r\n\r\nThe benchmarks are created in a simple and extensible way by\r\nemploying a rule-based data transformation language to extract\r\ninstance data from OpenStreetMap (OSM) geospatial data.\r\n\r\nDirectories in this repository are:\r\n\r\n* [cities](cities): pre-generated OWL files for selected cities\r\n* [queries](queries): predefined SPARQL queries\r\n* [tools](tools): data generation tools, which you can use to create your own benchmark\r\n* [mappings](mappings): a collection of mappings to generate the cities instances \r\n\r\nData Generation Tools\r\n---------------------\r\n\r\n`generate.py` is a Python 2.7 script that resembles the extract,\r\ntransform, and load (ETL) process of classical data transformation\r\ntools. The main input is the mapping file which contains ETL steps\r\nspecified in the next section. The only external library need is the\r\npsycopg2 (https://pypi.python.org/pypi/psycopg2), which is the\r\nPostgreSQL//PostGIS database adapter.\r\n\r\n```console $ generate.py --mappingFile file.txt --verbose ```\r\n\r\n`spatialRelationsReader.py` is an example implemenation of an external\r\nscript, which acts as a data source and calculates the spatial\r\nrelations (e.g., contains, next, etc.) between two input RDF files.\r\nThe files have to contain individuals with roles from GeoRSS (e.g.,\r\ngeo:point) assigned to them. As an external library shapely\r\n(https://pypi.python.org/pypi/Shapely) and GDAL is needed\r\n(http://trac.osgeo.org/gdal/wiki/GdalOgrInPython). The parameter \r\nfor the script are `relation file1 file2 distance`.\r\n\r\n`streetGraphReader.py` is another implementation of a  external script\r\nreader. In this reader the input are objects  represening different types of in OSM.\r\nFrom the objects and their geometry (e.g. geo:line) all the nodes and \r\nedges of the street graph are extracted. The parameter \r\nfor the script are `type` to chose between nodes/edges and `file`.\r\n\r\n\r\n`transformOSMConcepts.py` is a simple tranformation script for \r\nconverting OSM categories (e.g., restaurant) to concepts.\r\n\r\nMapping Language Syntax\r\n-----------------------\r\n\r\nA mapping file has two seperate sections. The first section is \r\nconcerned with general defintions as connection strings \r\nfor databases, file names, scripts, and simple constants. \r\nA line is ignored and treated a comment if it starts with `#`.\r\n\r\nThe following definitions are available, where `id` is the  \r\nreference which has to be used in the mapping axioms:\r\n\r\n* Postgres/PostGIS connections: `CONNECTION id: conn_string`\r\n\r\n   Connection are used for reading and writing from/to (geospatial) databases. We assume the standard data source name notation for conn_string, e.g.,\r\n   \r\n   `CONNECTION id1: HOST=localhost PORT=5432 DBNAME=test USER=postgres PASSWORD=secret`\r\n\r\n* Text files: `FILE id: file_string`\r\n\r\n   Any text file can function as an input/output source and is read/written line-by-line, where `file_string` has to contain `name=` to define the file url and optional `delimiter=' '`to define the field separator, e.g.,\r\n   \r\n   `FILE id2: name=/Users/patrik/test.csv delimiter=';'`\r\n   \r\n\r\n* Python scripts: `SCRIPT id: script_string`\r\n \r\n   Scripts are eiter used as input sources or as a transformation step for converting values. `script_string` is simply the url of the script file. For instance, \r\n\r\n   `SCRIPT id3: ./spatialRelationsReader.py`\r\n\r\n* Constants: `CONST id: const_string`\r\n\r\n   Constants are simple strings which are mainly used to write @prefix, @base, ow:imports to output files, e.g.,\r\n   \r\n   `CONST id4: @prefix  geo: <http://www.georss.org/georssl/>`\r\n\r\n\r\nThe second section contains the mapping axioms. An axiom defines a \r\nsingle ETL step, the syntax is an extension of the ontop mapping language \r\n(https://github.com/ontop/ontop/wiki/ObdalibObdaTurtlesyntax).\r\nA mapping axiom has an id and is defined either as a pair of `source` and `target`\r\nor as the triple of `source`, `transform`, and `target`:\r\n\r\n<pre>\r\nmappingId map_id\r\nsource source_id source_parameter\r\ntransform transform_id transform_parameter\r\ntarget target_id target_parameter\r\n</pre>\r\n\r\nAccording to the kind of source, it has to be configured accordingly, where \r\n `source_id` refers to the defintion:\r\n\r\n* Postgres/PostGIS relations: `connection_id  sql_statement`\r\n\r\n   The `connection_id` refers to `CONNECTION` from the defintions. \r\n`sql_statement` defines the SQL \"Select-From-Where\" statement which is\r\nexecuted on the refered database.  The result can be processed a set\r\nof n-tuples, which can be accessed by its index in the `target` step. For instance, \r\n\r\n   `source id1  SELECT osm_id, name, ST_AsEWKT(way) AS geo FROM planet_osm_polygon WHERE leisure = 'park'`, reads all the parks (spatial objects) from OSM.\r\n\r\n\r\n* Text files: `file_id reg_exp`\r\n\r\n   Text files are directly linked to the definition in `FILE`. The refered file is read line-by-line resulting in an n-tuple base on the field delimiter. If `reg_exp` is empty all lines are returned, otherwise only the line fulfilling the regular expression are returned. For instance, \r\n   \r\n   `source id2  (?)POINT\\(1[^>]*\\)}`, extracts all lines, which contain a \"Point\" geometry.\r\n\r\n* Python scripts:  `script_id parameter`\r\n\r\n    Scripts are the main option to extend the benchmark creation i.a. with the calculation of spatial relations. `parameter` are entered separated by space and can be either constant texts (in double quotes) or variables, which are replaced with the corresponding value on run time. Note that scripts are treated as a data source, hence the methods `open(parameter)` and `read()` have to be implemented.  In the read method n-tuples have to be returned by the python command `yield`.\r\n\r\n   `source id3 \"contains\" id2 id2`, which calls the spatialRelationsReader.py script to calculate the \"contains\" relation with the same file as the input\r\n\r\n* Constants: `constant c_id1 c_id2 ...`\r\n\r\n    Constants are the simplest sources and directly written to the target. It is possible to assign a sequence of constants to a single writing step.\r\n\r\n   `source constant id4`\r\n   \r\nThe targets `target target_id target_parameter` have to be configured according to the type \r\nof source:\r\n\r\n* Postgres/PostGIS relations: `connection_id  sql_statement`\r\n\r\n   The `connection_id` is as in the sources, 'sql_statement` defines the SQL \"Insert\" statement as \r\na template, which writes the n-tuples from the source into the database. E.g.,\r\n\r\n``` \r\n    target osm1 INSERT INTO table1 (subj, pred, obj) VALUES('{1}', '{2}', '{3}');\r\n```\r\n\r\n* Text files: `file_id output_text`\r\n\r\n   The `file_id` is as in the sources, 'output_text` is a textual template, which is written to the file. It can contain as single or multiple lines.  Usually, it will represent triples, which are used for the reasoner. For instance, \r\n\r\n``` \r\n    target f3  :{1} rdf:type tuwt:Playground, owl:NamedIndividual;\r\n               gml:featurename \"{2}\"^^xsd:string; \r\n               geo:polygon \"{3}\"^^xsd:string.\r\n```\r\n\r\n* Console: `stdout output_text`\r\n   For testing purposes, writing to the console is achieved by using `stdout`.\r\n\r\n\r\n\r\nContacts\r\n--------\r\n* [Thomas Eiter](http://www.kr.tuwien.ac.at/staff/eiter/)\r\n* [Patrik Schneider](http://www.kr.tuwien.ac.at/staff/patrik/)\r\n* [Mantas Simkus](http://www.dbai.tuwien.ac.at/staff/simkus/)\r\n* [Guohui Xiao](http://www.ghxiao.org)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}